{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LearnAI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natalievolk/LearnAI/blob/main/LearnAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWdwjqsPmZkF"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "\n",
        "# pillow to load image\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import requests\n",
        "from io import BytesIO\n",
        "#import urllib2\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iHIC3tJsire"
      },
      "source": [
        "# training data\n",
        "url_train = 'https://raw.githubusercontent.com/natalievolk/LearnAI/main/original-datasets/book30-listing-train.csv'\n",
        "data_train = pd.read_csv(url_train, index_col=False, usecols=[2,5], encoding = \"ISO-8859-1\")\n",
        "data_train.columns = ['jpg_url', 'classification']\n",
        "\n",
        "\n",
        "# testing data\n",
        "url_test = 'https://raw.githubusercontent.com/natalievolk/LearnAI/main/original-datasets/book30-listing-test.csv'\n",
        "data_test = pd.read_csv(url_test, index_col=False, usecols=[2,5], encoding = \"ISO-8859-1\")\n",
        "data_test.columns = ['jpg_url', 'classification']\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci3MhQOVu23l"
      },
      "source": [
        "# MAKING TRAINING SET\n",
        "\n",
        "file = open(\"train.txt\", 'w')\n",
        "#Image Preprocessing\n",
        " \n",
        "for index, image_name in enumerate(data_train['jpg_url']):\n",
        "    if image_name[-4:] == \".jpg\":\n",
        "      file.write(image_name + \" \" + str(data_train['classification'][index]) + \"\\n\")\n",
        "\n",
        "file.close()\n",
        "\n",
        "\n",
        "file = open(\"test.txt\",'w')\n",
        " \n",
        "for index, image_name in enumerate(data_test['jpg_url']):\n",
        "    if image_name[-4:] == \".jpg\":\n",
        "      file.write(image_name + \" \" + str(data_test['classification'][index]) + \"\\n\")\n",
        " \n",
        "file.close()\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OdHJpM5_qik"
      },
      "source": [
        "class ImagesDataset(Dataset):\n",
        "\n",
        "    def __init__(self, text_file):\n",
        "        self.df = pd.read_csv(text_file, sep=' ')\n",
        "        self.df.columns = ['jpg_url', 'classification']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        response = requests.get(self.df['jpg_url'][idx])\n",
        "        img = Image.open(BytesIO(response.content)).resize((400, 400))\n",
        "        pix = np.array(img)\n",
        " \n",
        "        return (pix, self.df['classification'][idx])\n",
        "\n",
        "#dataset = ImagesDataset('train.txt')\n",
        "#dataset[10]\n",
        "#len(dataset)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFzKW7uwNLpt"
      },
      "source": [
        "\n",
        "class Net(Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.cnn_layers = Sequential(\n",
        "            # Defining a 2D convolution layer\n",
        "            # in_channels = 3 (RGB), out_channels = 6\n",
        "            Conv2d(3, 6, kernel_size=5, stride=2, padding=0),\n",
        "            BatchNorm2d(6), # parameter = out_channels\n",
        "            ReLU(inplace=True),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Defining another 2D convolution layer\n",
        "            Conv2d(6, 12, kernel_size=7, stride=2, padding=0),\n",
        "            BatchNorm2d(12),\n",
        "            ReLU(inplace=True),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            Dropout(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.linear_layers = Sequential(\n",
        "            Linear(12 * 48 * 48, 128),\n",
        "            Linear(128, 64),\n",
        "            Linear(64, 32)\n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FwytecSQQYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2961d349-77e0-44f8-d24a-b04b8b772613"
      },
      "source": [
        "# defining the model\n",
        "model = Net()\n",
        "# defining the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.07)\n",
        "# defining the loss function\n",
        "criterion = CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "    \n",
        "print(model)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(2, 2))\n",
            "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(6, 12, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (5): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Dropout(p=0.2, inplace=True)\n",
            "  )\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=27648, out_features=128, bias=True)\n",
            "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtqZ01sTQWKk"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}